{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Chatbot - Step 2: Document Chunking & Embedding\n",
    "\n",
    "## Objectives:\n",
    "- Split documents into smaller chunks\n",
    "- Generate embeddings for each chunk\n",
    "- Prepare data for vector database\n",
    "\n",
    "## From EDA:\n",
    "- 20 documents, average 5,797 words\n",
    "- Recommended chunk size: 150 words\n",
    "- Recommended overlap: 30 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('âœ… Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data & EDA Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded!\n",
      "ðŸ“„ Number of documents: 20\n",
      "\n",
      "ðŸ“Š EDA Summary:\n",
      "  - num_documents: 20\n",
      "  - avg_doc_length: 5797.1\n",
      "  - median_doc_length: 3137.5\n",
      "  - num_single_passage_q: 40\n",
      "  - num_multi_passage_q: 40\n",
      "  - num_no_answer_q: 40\n",
      "  - recommended_chunk_size: 300\n",
      "  - recommended_overlap: 50\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "documents_df = pd.read_csv('../data_rag/documents.csv')\n",
    "\n",
    "# Load EDA summary\n",
    "with open('eda_summary.json', 'r') as f:\n",
    "    eda_summary = json.load(f)\n",
    "\n",
    "print('âœ… Data loaded!')\n",
    "print(f'ðŸ“„ Number of documents: {len(documents_df)}')\n",
    "print(f'\\nðŸ“Š EDA Summary:')\n",
    "for key, value in eda_summary.items():\n",
    "    print(f'  - {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Available columns:\n",
      "['index', 'source_url', 'text']\n",
      "\n",
      "âš ï¸ No ID column found, created index-based IDs\n",
      "\n",
      "âœ… Using columns:\n",
      "  - Text: text\n",
      "  - ID: id\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print('ðŸ“ Available columns:')\n",
    "print(documents_df.columns.tolist())\n",
    "\n",
    "# Set text column name - adjust if needed\n",
    "text_column = 'text'  # âš ï¸ Change this to match your column name\n",
    "id_column = 'id'      # âš ï¸ Change this if you have a document ID column\n",
    "\n",
    "# If no ID column exists, create one\n",
    "if id_column not in documents_df.columns:\n",
    "    documents_df['id'] = documents_df.index\n",
    "    id_column = 'id'\n",
    "    print('\\nâš ï¸ No ID column found, created index-based IDs')\n",
    "\n",
    "print(f'\\nâœ… Using columns:')\n",
    "print(f'  - Text: {text_column}')\n",
    "print(f'  - ID: {id_column}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Chunking\n",
    "###  à¸à¸Žà¸—à¸±à¹ˆà¸§à¹„à¸›:\n",
    "\n",
    "chunk_size = median Ã— 5-10%   à¸”à¸±à¸‡à¸™à¸±à¹‰à¸™  chunk_size = 3,137 Ã— 0.05 = 157 words\n",
    "\n",
    "overlap = chunk_size Ã— 15-20%  à¸”à¸±à¸‡à¸™à¸±à¹‰à¸™ chunk_size = 150 â†’ overlap = 30 words (20%)\n",
    "### Strategy:\n",
    "- **Chunk size**: 150 words (from EDA)\n",
    "- **Overlap**: 30 words (to preserve context)\n",
    "- **Method**: Word-based splitting (simple and effective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Calculated chunk size: 156 words\n",
      "ðŸ” Calculated overlap: 31 words\n"
     ]
    }
   ],
   "source": [
    "def calculate_chunk_size(documents_df, text_column='text'):\n",
    "    # à¸„à¸³à¸™à¸§à¸“ median (à¸”à¸µà¸à¸§à¹ˆà¸² average)\n",
    "    word_counts = documents_df[text_column].str.split().str.len()\n",
    "    median = word_counts.median()\n",
    "    \n",
    "    # Chunk = 5-7.5% à¸‚à¸­à¸‡ median\n",
    "    chunk_size = int(median * 0.05)  # à¸«à¸£à¸·à¸­ 0.075\n",
    "    chunk_overlap = int(chunk_size * 0.20)\n",
    "    \n",
    "    return chunk_size, chunk_overlap\n",
    "chunk_size, chunk_overlap = calculate_chunk_size(documents_df, text_column='text')\n",
    "print(f'\\nðŸ” Calculated chunk size: {chunk_size} words')\n",
    "print(f'ðŸ” Calculated overlap: {chunk_overlap} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunking function ready!\n",
      "Test: 500 words â†’ 4 chunks\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text: str, chunk_size:int , overlap: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks based on word count.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        chunk_size: Number of words per chunk\n",
    "        overlap: Number of overlapping words between chunks\n",
    "    \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # If text is shorter than chunk size, return as single chunk\n",
    "    if len(words) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(words):\n",
    "        # Get chunk\n",
    "        end = start + chunk_size\n",
    "        chunk_words = words[start:end]\n",
    "        \n",
    "        # Join words back to text\n",
    "        chunk = ' '.join(chunk_words)\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        # Move start position (with overlap)\n",
    "        start += chunk_size - overlap\n",
    "        \n",
    "        # Break if we've reached the end\n",
    "        if end >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test the function\n",
    "test_text = \"This is a test sentence. \" * 100\n",
    "test_chunks = chunk_text(test_text, chunk_size= chunk_size, overlap=chunk_overlap)\n",
    "print(f'âœ… Chunking function ready!')\n",
    "print(f'Test: {len(test_text.split())} words â†’ {len(test_chunks)} chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”ª Chunking documents...\n",
      "  - Chunk size: 156 words\n",
      "  - Overlap: 31 words\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 1111.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Chunking complete!\n",
      "ðŸ“„ Total documents: 20\n",
      "ðŸ“¦ Total chunks: 933\n",
      "ðŸ“Š Average chunks per document: 46.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'ðŸ”ª Chunking documents...')\n",
    "print(f'  - Chunk size: {chunk_size} words')\n",
    "print(f'  - Overlap: {chunk_overlap} words')\n",
    "print()\n",
    "\n",
    "all_chunks = []\n",
    "chunk_metadata = []\n",
    "\n",
    "for idx, row in tqdm(documents_df.iterrows(), total=len(documents_df), desc='Chunking'):\n",
    "    doc_id = row[id_column]\n",
    "    text = row[text_column]\n",
    "    \n",
    "    # Create chunks\n",
    "    chunks = chunk_text(text, chunk_size=chunk_size, overlap=chunk_overlap)\n",
    "    \n",
    "    # Store chunks with metadata\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        all_chunks.append(chunk)\n",
    "        chunk_metadata.append({\n",
    "            'doc_id': doc_id,\n",
    "            'chunk_id': chunk_idx,\n",
    "            'chunk_text': chunk,\n",
    "            'chunk_length': len(chunk.split())\n",
    "        })\n",
    "\n",
    "print(f'\\nâœ… Chunking complete!')\n",
    "print(f'ðŸ“„ Total documents: {len(documents_df)}')\n",
    "print(f'ðŸ“¦ Total chunks: {len(all_chunks)}')\n",
    "print(f'ðŸ“Š Average chunks per document: {len(all_chunks) / len(documents_df):.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Chunk Statistics:\n",
      "count    933.000000\n",
      "mean     154.603430\n",
      "std       10.805998\n",
      "min       35.000000\n",
      "25%      156.000000\n",
      "50%      156.000000\n",
      "75%      156.000000\n",
      "max      156.000000\n",
      "Name: chunk_length, dtype: float64\n",
      "\n",
      "ðŸ“ Sample Chunks:\n",
      "================================================================================\n",
      "\n",
      "Chunk 0 (Doc 0, Chunk 0):\n",
      "Length: 156 words\n",
      "Bullet Kin Bullet Kin are one of the most common enemies. They slowly walk towards the player, occasionally firing a single bullet. They can flip tables and use them as cover. They will also deal cont...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 1 (Doc 0, Chunk 1):\n",
      "Length: 156 words\n",
      "if there are any unoccupied Minecarts within the room, they will take priority by walking towards them to ride in. Trivia Bullet Kin wield Magnums. Assault-rifle wielding Bullet Kin wield AK-47s. Inca...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 2 (Doc 0, Chunk 2):\n",
      "Length: 156 words\n",
      "game Riverbond. Bullet Kin also has a cameo as lower and upper parts of a skin in the game Fall Guys: Ultimate Knockout. Veteran Bullet Kin Veteran Bullet Kin are similar to regular Bullet Kin, but ha...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyze chunk statistics\n",
    "chunk_df = pd.DataFrame(chunk_metadata)\n",
    "\n",
    "print('ðŸ“Š Chunk Statistics:')\n",
    "print(chunk_df['chunk_length'].describe())\n",
    "\n",
    "# Show sample chunks\n",
    "print('\\nðŸ“ Sample Chunks:')\n",
    "print('='*80)\n",
    "for i in range(min(3, len(all_chunks))):\n",
    "    print(f'\\nChunk {i} (Doc {chunk_df.iloc[i][\"doc_id\"]}, Chunk {chunk_df.iloc[i][\"chunk_id\"]}):')\n",
    "    print(f'Length: {chunk_df.iloc[i][\"chunk_length\"]} words')\n",
    "    print(all_chunks[i][:200] + '...')\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings\n",
    "\n",
    "### Embedding Model:\n",
    "- Using **sentence-transformers** (all-MiniLM-L6-v2)\n",
    "- Dimension: 384\n",
    "- Fast and efficient for retrieval tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading embedding model...\n",
      "âœ… Model loaded: BAAI/bge-base-en-v1.5\n",
      "ðŸ“ Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# Import sentence transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "print('â³ Loading embedding model...')\n",
    "model_name = 'BAAI/bge-base-en-v1.5'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "print(f'âœ… Model loaded: {model_name}')\n",
    "print(f'ðŸ“ Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test Embedding:\n",
      "  - Input: \"This is a test sentence for embedding.\"\n",
      "  - Output shape: (768,)\n",
      "  - First 5 values: [ 0.01576559 -0.03737001  0.02165025  0.0359973   0.07341885]\n"
     ]
    }
   ],
   "source": [
    "# Test embedding\n",
    "test_text = \"This is a test sentence for embedding.\"\n",
    "test_embedding = embedding_model.encode(test_text)\n",
    "\n",
    "print('ðŸ§ª Test Embedding:')\n",
    "print(f'  - Input: \"{test_text}\"')\n",
    "print(f'  - Output shape: {test_embedding.shape}')\n",
    "print(f'  - First 5 values: {test_embedding[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Generating embeddings for 933 chunks...\n",
      "âš ï¸ This may take a few minutes depending on your hardware.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2889334c43f4629a7da328f6afa76c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Embeddings generated!\n",
      "ðŸ“Š Shape: (933, 768)\n",
      "ðŸ’¾ Memory: 2.73 MB\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all chunks\n",
    "print(f'ðŸ”„ Generating embeddings for {len(all_chunks)} chunks...')\n",
    "print('âš ï¸ This may take a few minutes depending on your hardware.')\n",
    "print()\n",
    "\n",
    "# Encode in batches for efficiency\n",
    "batch_size = 32\n",
    "embeddings = embedding_model.encode(\n",
    "    all_chunks,\n",
    "    batch_size=batch_size,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f'\\nâœ… Embeddings generated!')\n",
    "print(f'ðŸ“Š Shape: {embeddings.shape}')\n",
    "print(f'ðŸ’¾ Memory: {embeddings.nbytes / (1024**2):.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Chunks and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings saved to: models/chunks/embeddings.npy\n",
      "âœ… Metadata saved to: models/chunks/chunk_metadata.csv\n",
      "âœ… Chunks data saved to: models/chunks/chunks_data.json\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "import os\n",
    "os.makedirs('models/chunks', exist_ok=True)\n",
    "\n",
    "# Save embeddings\n",
    "np.save('models/chunks/embeddings.npy', embeddings)\n",
    "print('âœ… Embeddings saved to: models/chunks/embeddings.npy')\n",
    "\n",
    "# Save chunk metadata\n",
    "chunk_df.to_csv('models/chunks/chunk_metadata.csv', index=False)\n",
    "print('âœ… Metadata saved to: models/chunks/chunk_metadata.csv')\n",
    "\n",
    "# Save chunks as JSON (for easier access)\n",
    "chunks_data = {\n",
    "    'chunks': all_chunks,\n",
    "    'metadata': chunk_metadata,\n",
    "    'config': {\n",
    "        'chunk_size': chunk_size,\n",
    "        'overlap': chunk_overlap,\n",
    "        'embedding_model': model_name,\n",
    "        'embedding_dim': embedding_model.get_sentence_embedding_dimension(),\n",
    "        'num_chunks': len(all_chunks),\n",
    "        'num_documents': len(documents_df)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/chunks/chunks_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(chunks_data, f, ensure_ascii=False, indent=2)\n",
    "print('âœ… Chunks data saved to: models/chunks/chunks_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Quality Check: Pairwise Similarities (first 5 chunks)\n",
      "Expected: Chunks from same document should have higher similarity\n",
      "\n",
      "Similarity Matrix:\n",
      "         Chunk 0  Chunk 1  Chunk 2  Chunk 3  Chunk 4\n",
      "Chunk 0    1.000    0.829    0.756    0.733    0.672\n",
      "Chunk 1    0.829    1.000    0.791    0.749    0.685\n",
      "Chunk 2    0.756    0.791    1.000    0.824    0.667\n",
      "Chunk 3    0.733    0.749    0.824    1.000    0.714\n",
      "Chunk 4    0.672    0.685    0.667    0.714    1.000\n"
     ]
    }
   ],
   "source": [
    "# Verify embeddings quality\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Test: Similar chunks should have high similarity\n",
    "# Take first 5 chunks from same document\n",
    "sample_chunks = all_chunks[:5]\n",
    "sample_embeddings = embeddings[:5]\n",
    "\n",
    "# Calculate pairwise similarities\n",
    "similarities = cosine_similarity(sample_embeddings)\n",
    "\n",
    "print('ðŸ” Quality Check: Pairwise Similarities (first 5 chunks)')\n",
    "print('Expected: Chunks from same document should have higher similarity')\n",
    "print()\n",
    "print('Similarity Matrix:')\n",
    "print(pd.DataFrame(\n",
    "    similarities,\n",
    "    columns=[f'Chunk {i}' for i in range(5)],\n",
    "    index=[f'Chunk {i}' for i in range(5)]\n",
    ").round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Test Retrieval: \"What is machine learning?\"\n",
      "\n",
      "Top 3 most similar chunks:\n",
      "================================================================================\n",
      "\n",
      "#1 | Similarity: 0.6003\n",
      "Doc ID: 2 | Chunk: 19\n",
      "Text: could have written a framework for loading, unloading, and executing the models, passing context and queries to the models, and integrating the vector...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#2 | Similarity: 0.5860\n",
      "Doc ID: 13 | Chunk: 7\n",
      "Text: for i in range(0, len(train_data) - ctx_len, ctx_len)]) X_val = mx.array([val_data[i:i+ctx_len] for i in range(0, len(val_data) - ctx_len, ctx_len)]) ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "#3 | Similarity: 0.5809\n",
      "Doc ID: 6 | Chunk: 13\n",
      "Text: for a variety of tasks. Individual models may be integrated into a large number of AI systems. It is important that a provider wishing to build upon a...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test: Find most similar chunk to a query\n",
    "test_query = \"What is machine learning?\"\n",
    "query_embedding = embedding_model.encode(test_query)\n",
    "\n",
    "# Calculate similarities\n",
    "query_similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "\n",
    "# Get top 3 most similar chunks\n",
    "top_k = 3\n",
    "top_indices = np.argsort(query_similarities)[::-1][:top_k]\n",
    "\n",
    "print(f'\\nðŸ”Ž Test Retrieval: \"{test_query}\"')\n",
    "print(f'\\nTop {top_k} most similar chunks:')\n",
    "print('='*80)\n",
    "\n",
    "for rank, idx in enumerate(top_indices, 1):\n",
    "    score = query_similarities[idx]\n",
    "    chunk_info = chunk_metadata[idx]\n",
    "    chunk_text = all_chunks[idx]\n",
    "    \n",
    "    print(f'\\n#{rank} | Similarity: {score:.4f}')\n",
    "    print(f'Doc ID: {chunk_info[\"doc_id\"]} | Chunk: {chunk_info[\"chunk_id\"]}')\n",
    "    print(f'Text: {chunk_text[:150]}...')\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Š CHUNKING & EMBEDDING SUMMARY\n",
      "================================================================================\n",
      "num_documents: 20\n",
      "num_chunks: 933\n",
      "chunks_per_doc: 46.65\n",
      "chunk_size: 156\n",
      "overlap: 31\n",
      "embedding_model: BAAI/bge-base-en-v1.5\n",
      "embedding_dim: 768\n",
      "avg_chunk_length: 154.60342979635584\n",
      "\n",
      "ðŸ“ Output Files:\n",
      "  - embeddings: models/chunks_bge/embeddings.npy\n",
      "  - metadata: models/chunks_bge/chunk_metadata.csv\n",
      "  - chunks_data: models/chunks_bge/chunks_data.json\n",
      "\n",
      "âœ… Step 2 Complete!\n",
      "ðŸ’¾ Summary saved to: models/chunks/chunking_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Create summary\n",
    "chunking_summary = {\n",
    "    'num_documents': len(documents_df),\n",
    "    'num_chunks': len(all_chunks),\n",
    "    'chunks_per_doc': len(all_chunks) / len(documents_df),\n",
    "    'chunk_size': chunk_size,\n",
    "    'overlap': chunk_overlap,\n",
    "    'embedding_model': model_name,\n",
    "    'embedding_dim': int(embedding_model.get_sentence_embedding_dimension()),\n",
    "    'avg_chunk_length': float(chunk_df['chunk_length'].mean()),\n",
    "    'output_files': {\n",
    "        'embeddings': 'models/chunks_bge/embeddings.npy',\n",
    "        'metadata': 'models/chunks_bge/chunk_metadata.csv',\n",
    "        'chunks_data': 'models/chunks_bge/chunks_data.json'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "with open('models/chunks_bge/chunking_summary.json', 'w') as f:\n",
    "    json.dump(chunking_summary, f, indent=2)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('ðŸ“Š CHUNKING & EMBEDDING SUMMARY')\n",
    "print('='*80)\n",
    "for key, value in chunking_summary.items():\n",
    "    if key != 'output_files':\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "print('\\nðŸ“ Output Files:')\n",
    "for key, path in chunking_summary['output_files'].items():\n",
    "    print(f'  - {key}: {path}')\n",
    "\n",
    "print('\\nâœ… Step 2 Complete!')\n",
    "print('ðŸ’¾ Summary saved to: models/chunks/chunking_summary.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
